{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC6MSNqIu7QM6gEu7ibw91"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeKIKOoESS0B"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Function to scrape reviews from a single page\n",
        "def scrape_page(url):\n",
        "    html_text = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}).text\n",
        "    soup = BeautifulSoup(html_text, 'html.parser')\n",
        "    reviews = soup.find_all('div', class_='styles_reviewCardInner__UZk1x')\n",
        "\n",
        "    # Initialize an empty list to store data from each page\n",
        "    page_data = []\n",
        "\n",
        "    for review in reviews:\n",
        "        try:\n",
        "            author_name = review.find('span', class_='typography_heading-xxs__UmE9o typography_appearance-default__t8iAq').text.strip()\n",
        "        except AttributeError:\n",
        "            author_name = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            review_text = review.find('p', class_='typography_body-l__v5JLj typography_appearance-default__t8iAq typography_color-black__wpn7m').text.strip()\n",
        "        except AttributeError:\n",
        "            review_text = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            date_published = review.find('p', class_='typography_body-m__k2UI7 typography_appearance-default__t8iAq').text.strip()\n",
        "        except AttributeError:\n",
        "            date_published = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            star_rating = review.find('div', class_='styles_reviewHeader__xV2js').find('img')['alt']\n",
        "        except AttributeError:\n",
        "            star_rating = \"N/A\"\n",
        "\n",
        "        # Append data for each review to the page_data list\n",
        "        page_data.append({\n",
        "            'Author Name': author_name,\n",
        "            'Review Message': review_text,\n",
        "            'Review Date': date_published,\n",
        "            'Star Rating': star_rating\n",
        "        })\n",
        "\n",
        "    return page_data\n",
        "\n",
        "# Main function to scrape multiple pages\n",
        "def scrape_multiple_pages(base_url, num_pages):\n",
        "    all_data = []  # Initialize an empty list to store data from all pages\n",
        "    for page_num in range(1, num_pages + 1):\n",
        "        url = f\"{base_url}?page={page_num}\"\n",
        "        print(f\"\\nScraping reviews from page {page_num}: {url}\\n\")\n",
        "        try:\n",
        "            page_data = scrape_page(url)\n",
        "            all_data.extend(page_data)  # Extend the list with data from the current page\n",
        "            time.sleep(2)  # Delay to avoid rate-limiting\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while scraping {url}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "# Example usage\n",
        "base_url = 'https://www.trustpilot.com/review/www.tescobank.com'\n",
        "num_pages = 1500  # Number of pages to scrape\n",
        "\n",
        "data = scrape_multiple_pages(base_url, num_pages)\n",
        "\n",
        "# Create and save DataFrame from the collected data\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('Tescobank.csv', index=False)\n",
        "df.to_excel('Tescobank.xlsx', index=False)\n",
        "print('Saved to file.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('Tescobank.csv')\n",
        "\n",
        "# Download the Excel file\n",
        "files.download('Tescobank.xlsx')"
      ],
      "metadata": {
        "id": "zhWwTPNmckV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}